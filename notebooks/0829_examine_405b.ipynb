{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "from transformers.models.llama.modeling_llama import LlamaRotaryEmbedding, LlamaForCausalLM\n",
    "from transformers.models.llama.configuration_llama import LlamaConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_layer2file[i]='/data_ephemeral/sim/sharded_layers_405b_interval1/llama3_1_405b/distill_llama3_1_405b_lk_smd_wtk64_fd64_w01/_scratch_rahul_models_Meta-Llama-3.1-405B-in=053-out=053.pt'; len(ref_layer2file)=110\n",
      "layer2file[i]={'path': '/home/simarora/code/lolcats/checkpoints/dl-d=llama3_1_405b/distill_llama_405b_xent1_mse1000_lr1e-2-m=llama3_1_405b/distill_llama3_1_405b_lk_smd_wtk64_fd64_w01-f=llama3_1_405b/finetune_layer_mini_xent1_mse1000-s=0-se=0-re=0-in=000-out=008_distill.pt', 'offset': 8}; len(layer2file)=126\n"
     ]
    }
   ],
   "source": [
    "# reference files\n",
    "fpath = \"/data_ephemeral/sim/sharded_layers_405b_interval1/llama3_1_405b/distill_llama3_1_405b_lk_smd_wtk64_fd64_w01/\"\n",
    "files = [f for f in os.listdir(fpath) if f.endswith('.pt')]\n",
    "ref_layer2file = {}\n",
    "for file in files:\n",
    "    start = file.split(\"in=\")[1].split(\"-\")[0].strip('.pt')\n",
    "    end   = file.split(\"out=\")[1].split(\"-\")[0].strip('.pt')\n",
    "    if int(start) == 0: start = int(end) - 1\n",
    "    for i in range(int(start), int(end)+1):\n",
    "        ref_layer2file[i] = fpath + file\n",
    "print(f\"{ref_layer2file[i]=}; {len(ref_layer2file)=}\")\n",
    "\n",
    "# trained files \n",
    "fpath = \"/home/simarora/code/lolcats/checkpoints/dl-d=llama3_1_405b/distill_llama_405b_xent1_mse1000_lr1e-2-m=llama3_1_405b/distill_llama3_1_405b_lk_smd_wtk64_fd64_w01-f=llama3_1_405b\"\n",
    "layer2file = {}\n",
    "for path in os.listdir(fpath): \n",
    "    new_path = fpath + '/' + path\n",
    "    start = new_path.split(\"in=\")[1].split(\"-\")[0]\n",
    "    end   = new_path.split(\"out=\")[1].split(\"_\")[0]\n",
    "    # print(start, end)\n",
    "    for ix, i in enumerate(range(int(start), int(end)+1)):\n",
    "        layer2file[i] = {\n",
    "            \"path\": new_path,\n",
    "            \"offset\": ix\n",
    "        }\n",
    "\n",
    "print(f\"{layer2file[i]=}; {len(layer2file)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the reference vs. trained for a good cria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed\n",
    "\n",
    "def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
    "    if n_rep == 1:\n",
    "        return hidden_states\n",
    "    hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
    "    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)\n",
    "\n",
    "def get_masks(window_size: int, q_len: int, k_len: int, \n",
    "              device: torch.device) -> tuple[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Return masks for softmax and linear attention terms\n",
    "    -> 1 is include, 0 is ignore\n",
    "    \"\"\"\n",
    "    kwargs = {'device': device, 'dtype': int}\n",
    "    l = window_size\n",
    "    m = math.ceil(max(q_len, k_len) / window_size)\n",
    "    # Creates an n x n mask where n = window_size^2\n",
    "    mask = torch.block_diag(*[torch.ones((l, l), )] * m)\n",
    "    mask += torch.roll(mask, -l, -1) # this adds the terracing\n",
    "    if mask.shape[0] > q_len:\n",
    "        mask = mask[-q_len:]\n",
    "    if mask.shape[1] > k_len:\n",
    "        mask = mask[:, -k_len:]\n",
    "    # Return softmax mask (window), linear attention mask\n",
    "    mask = mask[None, None, ...]  # b, h, q_len, k_len\n",
    "    return torch.tril(mask).to(**kwargs), torch.tril(1 - mask).to(**kwargs)\n",
    "\n",
    "def quadratic_attention(q: torch.Tensor, k: torch.Tensor, \n",
    "                               f_q: torch.Tensor, f_k: torch.Tensor,\n",
    "                               v: torch.Tensor,\n",
    "                               window_factor: torch.Tensor,\n",
    "                               linear_factor: torch.Tensor,\n",
    "                               window_size: int,\n",
    "                               eps: float = 1e-12,\n",
    "                               mask_value: float=-1e8):\n",
    "    \"\"\"\n",
    "    Hybrid attention combining sliding window and linear attentions\n",
    "    \"\"\"\n",
    "\n",
    "    mask_window, mask_linear = get_masks(window_size, q.shape[-2], k.shape[-2], q.device)\n",
    "\n",
    "    # print(q.shape, k.shape, f_q.shape, f_k.shape, v.shape)\n",
    "    # torch.Size([1, 128, 1024, 128]) torch.Size([1, 128, 1024, 128]) torch.Size([1, 128, 1024, 128]) torch.Size([1, 128, 1024, 128]) torch.Size([1, 128, 1024, 128])\n",
    "\n",
    "    # 1. Sliding window (softmax attention)\n",
    "    a_sm = torch.einsum('bhmd,bhnd->bhmn', q.float(), k.float()) * (k.shape[-1] ** -0.5)\n",
    "    a_sm = a_sm.masked_fill(~mask_window.bool(), mask_value)\n",
    "    a_sm_max = torch.amax(a_sm, dim=-1, keepdim=True)\n",
    "    a_sm   = window_factor * torch.exp(a_sm - a_sm_max)\n",
    "    sum_sm = a_sm.sum(dim=-1, keepdim=True)\n",
    "\n",
    "    # 2. Under window (linear attention)\n",
    "    a_ln = torch.einsum('bhmd,bhnd->bhmn', f_q.float(), f_k.float())\n",
    "    a_ln = linear_factor * a_ln.masked_fill(~mask_linear.bool(), 0)\n",
    "    sum_ln = a_ln.sum(dim=-1, keepdim=True)\n",
    "\n",
    "    # 3. Combine\n",
    "    a = ((a_sm + a_ln) / (sum_sm + sum_ln)).to(q.dtype)  # Save attention weights\n",
    "    y = torch.einsum('bhmn,bhnd->bhmd', a_sm + a_ln, v.float())\n",
    "    y = (y / (sum_sm + sum_ln)).to(q.dtype)\n",
    "    return y, a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "mse=tensor(0.4185)\n"
     ]
    }
   ],
   "source": [
    "# load model weights\n",
    "idx = 117\n",
    "ref_path = ref_layer2file[idx]\n",
    "ref = torch.load(ref_path)\n",
    "trained = layer2file[idx]['path']\n",
    "offset = layer2file[idx]['offset']\n",
    "tr = torch.load(trained)\n",
    "\n",
    "# extract weights\n",
    "q_proj = ref['model.layers.0.self_attn.q_proj.weight']\n",
    "k_proj = ref['model.layers.0.self_attn.k_proj.weight']\n",
    "v_proj = ref['model.layers.0.self_attn.v_proj.weight']\n",
    "o_proj = ref['model.layers.0.self_attn.o_proj.weight']\n",
    "tr_q_map = tr['model_state_dict'][f'model.layers.{offset}.self_attn.feature_map_q.mlp.layer']\n",
    "tr_k_map = tr['model_state_dict'][f'model.layers.{offset}.self_attn.feature_map_k.mlp.layer']\n",
    "window_factors = tr['model_state_dict'][f'model.layers.{offset}.self_attn.window_factors']\n",
    "\n",
    "# dimensions\n",
    "bs, seqlen = 1, 1024\n",
    "window_size = 64\n",
    "print(f\"{q_proj.shape=}; {k_proj.shape=}; {v_proj.shape}; {tr_q_map.shape=}; {tr_k_map.shape=}\")\n",
    "dim = q_proj.shape[0]\n",
    "feature_dim = tr_q_map.shape[0] // 2\n",
    "head_dim = 128\n",
    "\n",
    "num_heads = dim // head_dim\n",
    "num_key_value_heads = 8\n",
    "num_key_value_groups = num_heads // num_key_value_heads\n",
    "print(f\"{num_heads=}; {num_key_value_heads=}; {num_key_value_groups=}\")\n",
    "\n",
    "# input\n",
    "hidden_states = torch.randn(bs, seqlen, dim, dtype=torch.bfloat16)\n",
    "\n",
    "rotary_emb = LlamaRotaryEmbedding(\n",
    "    dim=dim,\n",
    "    max_position_embeddings=8192,\n",
    "    base=500000.0,\n",
    "    scaling_factor=8.0,\n",
    "    rope_type=\"llama3\",\n",
    "    config=LlamaConfig()\n",
    ")\n",
    "\n",
    "query_states = torch.einsum(\"de, ble -> ble\", q_proj, hidden_states)\n",
    "key_states = torch.einsum(\"de, ble -> bld\", k_proj, hidden_states)\n",
    "value_states = torch.einsum(\"de, ble -> bld\", v_proj, hidden_states)\n",
    "\n",
    "query_states = query_states.view(bs, seqlen, num_heads, head_dim).transpose(1, 2)\n",
    "key_states = key_states.view(bs, seqlen, num_key_value_heads, head_dim).transpose(1, 2)\n",
    "value_states = value_states.view(bs, seqlen, num_key_value_heads, head_dim).transpose(1, 2)\n",
    "position_ids = torch.arange(seqlen, dtype=torch.long, device=hidden_states.device).unsqueeze(0).expand(bs, -1)\n",
    "\n",
    "cos, sin = rotary_emb(value_states, position_ids)\n",
    "query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
    "\n",
    "key_states = repeat_kv(key_states, num_key_value_groups)\n",
    "value_states = repeat_kv(value_states, num_key_value_groups)\n",
    "\n",
    "# linear attention lolcats\n",
    "x = torch.einsum(\"hdf, bhld->bhlf\", tr_q_map, query_states)\n",
    "f_q = torch.cat([torch.softmax(x, dim=-1), torch.softmax(-x, dim=-1)], dim=-1).clamp(min=1e-12)\n",
    "x = torch.einsum(\"hdf, bhld->bhlf\", tr_k_map, key_states)\n",
    "f_k = torch.cat([torch.softmax(x, dim=-1), torch.softmax(-x, dim=-1)], dim=-1).clamp(min=1e-12)\n",
    "window_factors = F.sigmoid(window_factors)\n",
    "linear_factors = 1\n",
    "y_pred, a_pred = quadratic_attention(\n",
    "    query_states, key_states,\n",
    "     f_q, f_k, value_states,\n",
    "    window_factors, linear_factors,\n",
    "    window_size=window_size\n",
    ")\n",
    "y_pred = y_pred.transpose(1, 2).contiguous().view(bs, seqlen, dim)\n",
    "y_pred = torch.einsum(\"de, ble -> ble\", o_proj, y_pred)\n",
    "\n",
    "# standard attention \n",
    "a_true = torch.nn.functional.scaled_dot_product_attention(\n",
    "    query_states, key_states, value_states,\n",
    "    attn_mask=None, dropout_p=0.0, is_causal=True,\n",
    ")\n",
    "y_true = a_true.transpose(1, 2).contiguous().view(bs, seqlen, dim)\n",
    "y_true = torch.einsum(\"de, ble -> ble\", o_proj, y_true)\n",
    "\n",
    "\n",
    "mse = torch.nn.functional.mse_loss(y_pred.float(), y_true.float())\n",
    "print(f\"{mse=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_217131/4032937699.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ref = torch.load(ref_path)\n",
      "/tmp/ipykernel_217131/4032937699.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tr = torch.load(trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n",
      "q_proj.shape=torch.Size([16384, 16384]); k_proj.shape=torch.Size([1024, 16384]); torch.Size([1024, 16384]); tr_q_map.shape=torch.Size([128, 128, 64]); tr_k_map.shape=torch.Size([128, 128, 64])\n",
      "num_heads=128; num_key_value_heads=8; num_key_value_groups=16\n"
     ]
    }
   ],
   "source": [
    "# load model weights\n",
    "layer2mse = {}\n",
    "\n",
    "for idx in ref_layer2file.keys():\n",
    "    try:\n",
    "        ref_path = ref_layer2file[idx]\n",
    "        ref = torch.load(ref_path)\n",
    "        trained = layer2file[idx]['path']\n",
    "        offset = layer2file[idx]['offset']\n",
    "        tr = torch.load(trained)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # extract weights\n",
    "    q_proj = ref['model.layers.0.self_attn.q_proj.weight']\n",
    "    k_proj = ref['model.layers.0.self_attn.k_proj.weight']\n",
    "    v_proj = ref['model.layers.0.self_attn.v_proj.weight']\n",
    "    o_proj = ref['model.layers.0.self_attn.o_proj.weight']\n",
    "    tr_q_map = tr['model_state_dict'][f'model.layers.{offset}.self_attn.feature_map_q.mlp.layer']\n",
    "    tr_k_map = tr['model_state_dict'][f'model.layers.{offset}.self_attn.feature_map_k.mlp.layer']\n",
    "    window_factors = tr['model_state_dict'][f'model.layers.{offset}.self_attn.window_factors']\n",
    "\n",
    "    # dimensions\n",
    "    bs, seqlen = 1, 1024\n",
    "    window_size = 64\n",
    "    print(f\"{q_proj.shape=}; {k_proj.shape=}; {v_proj.shape}; {tr_q_map.shape=}; {tr_k_map.shape=}\")\n",
    "    dim = q_proj.shape[0]\n",
    "    feature_dim = tr_q_map.shape[0] // 2\n",
    "    head_dim = 128\n",
    "\n",
    "    num_heads = dim // head_dim\n",
    "    num_key_value_heads = 8\n",
    "    num_key_value_groups = num_heads // num_key_value_heads\n",
    "    print(f\"{num_heads=}; {num_key_value_heads=}; {num_key_value_groups=}\")\n",
    "\n",
    "    # input\n",
    "    hidden_states = torch.randn(bs, seqlen, dim, dtype=torch.bfloat16)\n",
    "\n",
    "    rotary_emb = LlamaRotaryEmbedding(\n",
    "        dim=dim,\n",
    "        max_position_embeddings=8192,\n",
    "        base=500000.0,\n",
    "        scaling_factor=8.0,\n",
    "        rope_type=\"llama3\",\n",
    "        config=LlamaConfig()\n",
    "    )\n",
    "\n",
    "    query_states = torch.einsum(\"de, ble -> ble\", q_proj, hidden_states)\n",
    "    key_states = torch.einsum(\"de, ble -> bld\", k_proj, hidden_states)\n",
    "    value_states = torch.einsum(\"de, ble -> bld\", v_proj, hidden_states)\n",
    "\n",
    "    query_states = query_states.view(bs, seqlen, num_heads, head_dim).transpose(1, 2)\n",
    "    key_states = key_states.view(bs, seqlen, num_key_value_heads, head_dim).transpose(1, 2)\n",
    "    value_states = value_states.view(bs, seqlen, num_key_value_heads, head_dim).transpose(1, 2)\n",
    "    position_ids = torch.arange(seqlen, dtype=torch.long, device=hidden_states.device).unsqueeze(0).expand(bs, -1)\n",
    "\n",
    "    cos, sin = rotary_emb(value_states, position_ids)\n",
    "    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
    "\n",
    "    key_states = repeat_kv(key_states, num_key_value_groups)\n",
    "    value_states = repeat_kv(value_states, num_key_value_groups)\n",
    "\n",
    "    # linear attention lolcats\n",
    "    x = torch.einsum(\"hdf, bhld->bhlf\", tr_q_map, query_states)\n",
    "    f_q = torch.cat([torch.softmax(x, dim=-1), torch.softmax(-x, dim=-1)], dim=-1).clamp(min=1e-12)\n",
    "    x = torch.einsum(\"hdf, bhld->bhlf\", tr_k_map, key_states)\n",
    "    f_k = torch.cat([torch.softmax(x, dim=-1), torch.softmax(-x, dim=-1)], dim=-1).clamp(min=1e-12)\n",
    "    window_factors = F.sigmoid(window_factors)\n",
    "    linear_factors = 1\n",
    "    y_pred, a_pred = quadratic_attention(\n",
    "        query_states, key_states,\n",
    "        f_q, f_k, value_states,\n",
    "        window_factors, linear_factors,\n",
    "        window_size=window_size\n",
    "    )\n",
    "    y_pred = y_pred.transpose(1, 2).contiguous().view(bs, seqlen, dim)\n",
    "    y_pred = torch.einsum(\"de, ble -> ble\", o_proj, y_pred)\n",
    "\n",
    "    # standard attention \n",
    "    a_true = torch.nn.functional.scaled_dot_product_attention(\n",
    "        query_states, key_states, value_states,\n",
    "        attn_mask=None, dropout_p=0.0, is_causal=True,\n",
    "    )\n",
    "    y_true = a_true.transpose(1, 2).contiguous().view(bs, seqlen, dim)\n",
    "    y_true = torch.einsum(\"de, ble -> ble\", o_proj, y_true)\n",
    "\n",
    "\n",
    "    mse = torch.nn.functional.mse_loss(y_pred.float(), y_true.float())\n",
    "    layer2mse[idx] = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# sort and plot \n",
    "layer2mse = {k: v for k, v in sorted(layer2mse.items(), key=lambda item: item[1])}\n",
    "plt.plot(layer2mse.values())\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
